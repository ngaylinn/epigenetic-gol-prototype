"""Run all experiments and rebuild result summaries to embed in README.md.

This project is a demo of a self-optimizing genetic algorithm. The README file
contains an overview of the experiment's purpose, design, and results. The
graphs, images, and videos referenced by the README are all produced by running
this script and stored in the output directory.

Here is an overview of the files generated by this script:
output
    # Results from experiments to evolve a GenomeConfig for every fitness goal.
    genome_experiments
        <fitness_goal>
            # Results using different parameters for GenomeConfig evolution.
            <variation_name>
                best_config.pickle
                best_config.txt
                best_simulation.gif
                best_trials.svg
                fitness.svg
                state.pickle
    # Examples of unevolved individuals for each GenomeConfig
    sample_initial_populations
        <genome_config>
            <simulation_id>.gif
    # Results from experiments run on a single GenomeConfig
    simulation_experiments
        <fitness_goal>
            # Comparisons between single-config experiments.
            compare_evolved_configs_cross_task.svg
            compare_evolved_variations.svg
            compare_predefined_to_evolved_configs.svg
            # The experiment results for each GenomeConfig.
            <genome_config>
                best_simulation.gif
                fitness.svg
                state.pickle
"""

import os
import pickle

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns

import experiments
import fitness
import genome
import gol_simulation


def make_title(name):
    """Reformat a snake case string into a title case string.

    This project uses snake case for filenames and dictionary keys. It uses the
    same name for chart titles and labels, but transformed with this function.
    """
    return name.replace('_', ' ').title().replace(' X ', ' x ')


def genome_config_comparison_figure(all_fitness_data, title):
    """Generate a figure comparing GenomeConfig performance head to head.

    The figure produced has two charts. The first shows the fitness over
    generations of simulations evolved with each GenomeConfig. A median
    operation is used to aggregate data across trials. The second chart
    summarizes the max fitness scores found for each GenomeConfig, using a
    boxplot to show the spread of values across trials.

    Parameters
    ----------
    all_fitness_data : pd.DataFrame
        A collection of fitness data for all GenomeConfigs being compared,
        across generations in multiple trials.
    title : str
        A name for this comparison, used to title the chart.

    Returns
    -------
    plt.Figure
        A figure visualizing the comparative performance of different
        GenomeConfigs.
    """
    fig, axes = plt.subplots(1, 2, figsize=(12, 5))
    fig.suptitle(title)
    sns.lineplot(
        data=all_fitness_data, x='Generation', y='Fitness',
        hue='GenomeConfig', estimator=np.median, ax=axes[0],
    ).set(title='Median By Generation')
    sns.move_legend(
        axes[0], 'center left', bbox_to_anchor=(1, .5), frameon=False)
    sns.boxplot(
        data=all_fitness_data, x='GenomeConfig', y='Fitness', ax=axes[1]
    ).set(title='Max By Trials', xticklabels=[])
    plt.tight_layout()
    return fig


def compare_configs(comparison_name, per_fitness_configs):
    """Compare the performance of simulations with different GenomeConfigs.

    This project explores how different GenomeConfigs make it easier or harder
    to evolve a good GameOfLifeSimulation for a variety of fitness goals. A key
    task is to compare the performance of several SimulationLineages, each
    configured with a different GenomeConfig, to see which one was better at
    learning or produced the best results.

    This function runs all the experiments for such a contest between
    GenomeConfigs (or restores their results from disk). It then generates a
    chart for each experiment summarizing the performance of a single
    GenomeConfig, records a video of that experiment's best simulation, and
    generates a chart comparing the results of all the experiments side by side
    (see genome_config_comparison_figure).

    Parameters
    ----------
    comparison_name : str
        A brief description of used to name a chart that summarizes the
        comparison being made.
    per_fitness_configs : dict of str : dict of str : GenomeConfig
        A mapping from fitness goal to the set of GenomeConfigs to evaluate
        against that fitness goal. This is represented by a two-level tree of
        dictionaries. The outer dictionary is keyed by the name of the
        fitness_goal and the inner dictionary maps a name to a GenomeConfig.
    """
    for fitness_name, config_dict in per_fitness_configs.items():
        path = f'output/simulation_experiments/{fitness_name}'
        fitness_func = fitness.ALL_GOALS[fitness_name]
        all_fitness_data = pd.DataFrame()
        for config_name, genome_config in config_dict.items():
            subpath = f'{path}/{config_name}'
            os.makedirs(subpath, exist_ok=True)
            data = experiments.simulation_experiment(
                f'{subpath}/state.pickle', config_name,
                fitness_func, genome_config)

            # Chart the results of this single-config experiment.
            fitness_data = data['fitness_data']
            fig = sns.relplot(data=fitness_data, kind='line',
                              x='Generation', y='Fitness', hue='Trial')
            fig.set(title=make_title(config_name))
            fig.savefig(f'{subpath}/fitness.svg')
            plt.close()

            # Build up a DataFrame with the results from all experiments, keyed
            # by the GenomeConfig name.
            fitness_data['GenomeConfig'] = make_title(config_name)
            all_fitness_data = pd.concat((all_fitness_data, fitness_data))

            # Save the best simulation from this experiment.
            best_simulation = data['best_simulation']
            gol_simulation.record_single_video(
                best_simulation, f'{subpath}/best_simulation.gif')
        # Make a chart summarizing all the experiments side by side.
        genome_config_comparison_figure(
            all_fitness_data, make_title(comparison_name)
        ).savefig(f'{path}/{comparison_name}.svg')
        plt.close()


def make_sample_populations(genome_configs):
    """Save samples of random simulations made with different GenomeConfigs.

    This function is used to show what the initial population of simulations
    from each GenomeConfig looks before it gets evolved by a SimulationLineage.
    """
    for config_name, genome_config in genome_configs.items():
        path = f'output/sample_initial_populations/{config_name}'
        os.makedirs(path, exist_ok=True)
        # This is mostly to remove any discrepencies that might come from
        # running this function multiple times with different arguments.
        experiments.reset_global_state()
        population = [
            gol_simulation.GameOfLifeSimulation(genome.Genotype(genome_config))
            for _ in range(experiments.POPULATION_SIZE)]
        gol_simulation.record_videos(population, path)


def evolve_all_genome_config_variations(fitness_name, fitness_func):
    """Evolves GenomeConfigs for a fitness function, with different settings.

    This project uses the GenomeConfig class to optimize the genetic algorithm
    in three distinct ways: tuning global mutation and crossover rates, using a
    FitnessVector to condition those rates on recent performance, and tuning
    mutation rates on a fine-grain, gene-by-gene basis.

    Evovled global mutation and crossover rates are not unheard-of in the world
    of genetic algorithms. For this project, they are considered baseline
    behavior for an evolved GenomeConfig against which the other techniques are
    compared. For that reason, we test four variations to measure the impact of
    FitnessVectors and fine-grain mutations, independently and together.

    This function evolves GenomeConfigs to fit the given fitness goal in each
    of these four configurations. For each one, it makes a chart summarizing
    the performance of the GenomeLineage over the whole experiment, copies of
    the GenomeConfig in plaintext and pickle format so it can be inspected or
    reused, a fitness chart for the SimulationLineage run with the most fit
    evolved GenomeConfig, and a video of the best simulation from that run.

    Parameters
    ----------
        fitness_name : str
            The name of the fitness goal, used for naming files.
        fitness_func : Callable
            The function to evaluate the fitness of a simulation.

    Returns
    -------
    dict of str : GenomeConfig
        A mapping from configuration name to the best GenomeConfig found in
        that configuration, used to compare their performance.
    """
    best_config_per_variation = {}
    for variation_name, args in experiments.CONFIG_VARIATIONS.items():
        path = f'output/genome_experiments/{fitness_name}/{variation_name}'
        os.makedirs(path, exist_ok=True)
        data = experiments.genome_experiment(
            f'{path}/state.pickle', variation_name, fitness_func, *args)

        # Record the best GenomeConfig found.
        best_config = data['best_config']
        best_config_per_variation[variation_name] = best_config
        with open(f'{path}/best_config.pickle', 'wb') as file:
            pickle.dump(best_config, file)
        with open(f'{path}/best_config.txt', 'w', encoding='utf-8') as file:
            file.write(str(best_config))

        # Chart fitness for this GenomeLineage experiment.
        fig = sns.relplot(data=data['fitness_data'], kind='line',
                          x='Generation', y='Fitness')
        fig.set(title=make_title(variation_name))
        fig.savefig(f'{path}/fitness.svg')
        plt.close()

        # Chart fitness for all the SimulationLineage trials run for the best
        # evolved GenomeConfig
        fig = sns.relplot(data=data['best_fitness_data'], kind='line',
                          x='Generation', y='Fitness', hue='Trial')
        fig.set(
            title=make_title(f'Best Trials ({make_title(variation_name)})'))
        fig.savefig(f'{path}/best_trials.svg')
        plt.close()

        # Record a video of the best simulation made from the best evolved
        # GenomeConfig
        gol_simulation.record_single_video(
            data['best_simulation'], f'{path}/best_simulation.gif')
    return best_config_per_variation


def main():
    """Run experiments and summarize their results in the output directory."""
    sns.set_theme()

    # Select which fitness goals to analyze.
    fitness_goals = {
        name: func for name, func in fitness.ALL_GOALS.items()
        if name in ['explode', 'left_to_right', 'symmetry',
                    'two_cycle', 'three_cycle']}

    # Evolve GenomeConfigs for every fitness goal, with and without fitness
    # vectors and fine-grain mutations enabled.
    all_evolved_configs = {}
    best_evolved_configs = {}
    for fitness_name, fitness_func in fitness_goals.items():
        evolved_configs = evolve_all_genome_config_variations(
            fitness_name, fitness_func)
        all_evolved_configs[fitness_name] = evolved_configs
        best_evolved_configs[
            f'evolved_for_{fitness_name}'] = max(evolved_configs.values())

    # Compare the performance of the GenomeConfigs evolved with and without
    # fitness vectors and fine-grain mutations. This shows the effect those
    # variations had on the genetic algorithm, both separately and together.
    compare_configs('compare_evolved_variations', all_evolved_configs)

    # Compare the performance of the best evolved GenomeConfig for each fitness
    # goal on all of the fitness goals, including the ones it wasn't evolved
    # for. This shows how task-specific each GenomeConfig has evolved to be.
    compare_configs('compare_evolved_configs_cross_task',
                    {fitness_name: best_evolved_configs
                     for fitness_name in fitness_goals})

    # For each fitness function, compare the performance of the predefined
    # GenomeConfigs against the best one evolved for that fitness goal.
    compare_configs(
        'compare_predefined_to_evolved_configs',
        {fitness_name: {
            config_name: evolved_config
            for config_name, evolved_config in best_evolved_configs.items()
            if fitness_name in config_name} | genome.PREDEFINED_CONFIGS
         for fitness_name in fitness_goals})

    # Save an example initial population to document the behavior of the
    # GenomeConfigs evaluated above.
    make_sample_populations(genome.PREDEFINED_CONFIGS | best_evolved_configs)


if __name__ == '__main__':
    main()
